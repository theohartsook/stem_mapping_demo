{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the challenges for automated stem mapping is that the paremeters for stem mapping require existing knowledge about the plot, such as how many trees could reasonably exist and their sizes. Otherwise the search space is so large that automatic detections are inpractical due to low precision. This notebook demonstrates how we can limit the search space into something more reasonable for automatic stem mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the necessary libraries\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from math import floor\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from scipy import ndimage\n",
    "\n",
    "from skimage.draw import circle_perimeter, line\n",
    "from skimage import filters, measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This 5x5 m plot has several trees we want to detect, as well as noise from a fallen log and several shrubs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = Image.open('data/cluster_segmentation/cross_section.jpg')\n",
    "input_img = np.array(input_img)\n",
    "\n",
    "# multiplying the intesity values 100 makes it easier to see\n",
    "plt.imshow(input_img*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing to note is that while the total area is 5x5 meters, much of that area is empty space. A distance transform can find the natural boundaries between groups of pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = ndimage.distance_transform_edt(np.logical_not(input_img))\n",
    "\n",
    "plt.imshow(dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A ridge following algorithm forms connects segments of high distance pixels. The Meijering algorithm was originally developed for identifying neurites from medical images. Black ridges is set to false because we want to segment areas with high distances from other pixels. The thickness of the segment corresponds to the distaces between areas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridges = filters.meijering(dist, black_ridges=False)\n",
    "plt.imshow(ridges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These ridges separate the image into clusters of pixels. Connected component assigns each pixel into one of those clusters. This 5x5m image is now divided into 27 smaller images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensions = ridges.shape\n",
    "blobs = ridges.copy()\n",
    "for i in range(0, dimensions[0]):\n",
    "    for j in range(0, dimensions[1]):\n",
    "        pixel = ridges[i][j]\n",
    "        if pixel < 0.5:\n",
    "            blobs[i][j] = 1\n",
    "        else:\n",
    "            blobs[i][j] = 0\n",
    "blobs_labels = measure.label(blobs, connectivity=1)\n",
    "\n",
    "plt.imshow(blobs_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These clusters can be used to mask the original image. I defined some convenience functions below that I will use to crop the images to focus on just the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here are three convenience functions to clean up the clusters\n",
    "\n",
    "def trim2DArray(input_arr, threshold=0):  \n",
    "    print(input_arr.shape)\n",
    "    ul_x, ul_y = calculateTrimOffsetForward(input_arr, threshold)\n",
    "    lr_x, lr_y = calculateTrimOffsetBackward(input_arr, threshold)\n",
    "\n",
    "    output_arr = input_arr[ul_y:lr_y, ul_x:lr_x]\n",
    "\n",
    "    print(output_arr.shape)\n",
    "\n",
    "    return (output_arr)\n",
    "\n",
    "def calculateTrimOffsetForward(input_arr, threshold=0):\n",
    "    ul_x, ul_y = 0, 0\n",
    "\n",
    "    row_sum = np.sum(input_arr, axis=1)\n",
    "    col_sum = np.sum(input_arr, axis=0)\n",
    "\n",
    "    for i in range(0, len(col_sum)):\n",
    "        if col_sum[i] > threshold:\n",
    "            ul_x = i\n",
    "            break\n",
    "    for j in range(0, len(row_sum)):     \n",
    "        if row_sum[j] > threshold:\n",
    "            ul_y = j\n",
    "            break\n",
    "    return (ul_x, ul_y)\n",
    "\n",
    "def calculateTrimOffsetBackward(input_arr, threshold=0):\n",
    "    y,x = input_arr.shape\n",
    "    lr_x, lr_y = 0, 0\n",
    "\n",
    "    row_sum = np.sum(np.flip(input_arr), axis=1)\n",
    "    col_sum = np.sum(np.flip(input_arr), axis=0)\n",
    "\n",
    "    for i in range(0, len(col_sum)):\n",
    "        if col_sum[i] > threshold:\n",
    "            lr_x = i\n",
    "            break\n",
    "    for j in range(0, len(row_sum)):     \n",
    "        if row_sum[j] > threshold:\n",
    "            lr_y = j\n",
    "            break\n",
    "    return (x-lr_x, y-lr_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can investigate each of the clusters individually. I picked out some clusters to see below. The fact that this cluster has a roughly square bounding box is good a sign. We're looking for circles and circles are contained by squares. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_6 = np.where(blobs_labels == 6, True, False)\n",
    "\n",
    "trimmed_6 = trim2DArray(cluster_6)\n",
    "\n",
    "plt.imshow(trimmed_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use that cluster to mask the original image and see what caused it. This is one of the best case scenarios for a cluster because there is one tree and practically no noise. It will be easy to search this image for circles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ul_x, ul_y = calculateTrimOffsetForward(cluster_6)\n",
    "lr_x, lr_y = calculateTrimOffsetBackward(cluster_6)\n",
    "\n",
    "one_tree = cluster_6*input_img\n",
    "\n",
    "trimmed_tree = one_tree[ul_y:lr_y,ul_x:lr_x]\n",
    "\n",
    "plt.imshow(trimmed_tree*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take a look at a cluster of noise. This very rectangular bounding box is not a good sign, because the pixels here are probably not a circle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_11 = np.where(blobs_labels == 11, True, False)\n",
    "\n",
    "trimmed_11 = trim2DArray(cluster_11)\n",
    "\n",
    "plt.imshow(trimmed_11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After applying this cluster as a mask, we can see that this is the log from the lower left corner of the original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ul_x, ul_y = calculateTrimOffsetForward(cluster_11)\n",
    "lr_x, lr_y = calculateTrimOffsetBackward(cluster_11)\n",
    "\n",
    "noise = cluster_11*input_img\n",
    "\n",
    "trimmed_noise = noise[ul_y:lr_y,ul_x:lr_x]\n",
    "\n",
    "plt.imshow(trimmed_noise*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These clusters are important for many reasons.\n",
    "* The maximum size of a circle in a cluster is half the shortest side of the cluster's bounding box\n",
    "* The area of the cluster limits the maximum number of trees that can be found\n",
    "* Clusters that have a side smaller than min_r/2 can be excluded\n",
    "* Limiting the search space of Hough transforms reduces false positives\n",
    "* Boundaries between clusters are areas with no pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the trimmed tree, this means that we can limit the search space to circles with a radius between min_r and 0.57 m."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_cir = trimmed_tree.copy()\n",
    "\n",
    "l, w = max_cir.shape\n",
    "c_x = floor(w/2)\n",
    "c_y = floor(l/2)\n",
    "\n",
    "if l > w:\n",
    "    print(\"the shortest side is\", w)\n",
    "    r = line(c_y, c_x, c_y, 0)\n",
    "    sub_y, sub_x = circle_perimeter(c_y, c_x, c_x-1)\n",
    "else:\n",
    "    print(\"the shortest side is\", l)\n",
    "    r = line(c_y, c_x, 0, c_x)\n",
    "    sub_y, sub_x = circle_perimeter(c_y, c_x, c_y-1)\n",
    "\n",
    "\n",
    "\n",
    "max_cir[r] = 255\n",
    "max_cir[sub_y, sub_x] = 255\n",
    "\n",
    "plt.imshow(max_cir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the log cluster, the maximum radius is particularly useful. Even though the image is very tall, we only need to look for circles between min_r and 0.34 meters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_cir = trimmed_noise.copy()\n",
    "\n",
    "l, w = max_cir.shape\n",
    "c_x = floor(w/2)\n",
    "c_y = floor(l/2)\n",
    "\n",
    "if l > w:\n",
    "    print(\"the shortest side is\", w)\n",
    "    r = line(c_y, c_x, c_y, 0)\n",
    "    sub_y, sub_x = circle_perimeter(c_y, c_x, c_x)\n",
    "else:\n",
    "    print(\"the shortest side is\", l)\n",
    "    r = line(c_y, c_x, 0, c_x)\n",
    "    sub_y, sub_x = circle_perimeter(c_y, c_x, c_y)\n",
    "\n",
    "\n",
    "\n",
    "max_cir[r] = 255\n",
    "max_cir[sub_y, sub_x] = 255\n",
    "\n",
    "plt.imshow(max_cir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
